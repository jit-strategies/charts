replicaCount: 1

image:
  repository: makemake1337/blutgang
  pullPolicy: IfNotPresent
  tag: "latest"

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

config: |
  [blutgang]
  # Clear the cache DB on startup
  do_clear = false
  # Where to bind blutgang to
  address = "0.0.0.0:{{ .Values.httpPort }}"
  # Moving average length for the latency
  ma_length = 10
  # Sort RPCs by latency on startup. Recommended to leave on.
  sort_on_startup = true
  # Enable health checking
  health_check = true
  # Acceptable time to wait for a response in ms
  ttl = 300
  # How many times to retry a request before giving up
  max_retries = 32
  # Time between health checks in ms
  health_check_ttl = 12000
  
  # Note: the admin namespace contains volatile functions and
  # should not be exposed publicly.
  [admin]
  # Enable the admin namespace
  enabled = false
  # Address for the admin RPC
  address = "0.0.0.0:{{ .Values.adminRPCPort }}"
  # Only allow read-only methods
  # Recommended `true` unless you 100% need write methods
  readonly = true
  # Enable the use of JWT for auth
  # Should be on if exposing to the internet
  jwt = false
  # jwt token
  token = ""
  
  # Sled config
  # Sled is the database we use for our cache, for more info check their docs
  [sled]
  # Path to db
  db_path = "./blutgang-cache"
  # sled mode. Can be HighThroughput/LowSpace
  mode = "HighThroughput"
  # Cache size in bytes. Doesn't matter too much as you OS should also be caching.
  cache_capacity = 1000000000
  # Use zstd compression. Reduces size 60-70%,
  # and increases CPU and latency by around 10% for db writes and 2% for reads
  compression = false
  # Print DB profile when dropped. Doesn't do anything for now.
  print_profile = false
  # Frequency of flushes in ms
  flush_every_ms = 24000
  
  # Add seperate RPCs as TOML tables
  # DO NOT name an rpc `blutgang`, `admin`, or `sled`
  [llama]
  # RPC url
  url = "https://eth.llamarpc.com"
  # The maximum ammount of time we can use this rpc in a row.
  max_consecutive = 5
  # Max ammount of querries per second. Doesn't do anything for now.
  max_per_second = 0

httpPort: 3000
adminRPCPort: 5715
serviceAccount:
  create: false
  automount: true
  annotations: {}
  name: ""

podAnnotations: {}
podLabels: {}

podSecurityContext: {}
  # fsGroup: 2000

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

service:
  type: ClusterIP

ingress:
  enabled: false
  className: ""
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths:
        - path: /
          pathType: ImplementationSpecific
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

resources: {}
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

volumes: []
# - name: foo
#   secret:
#     secretName: mysecret
#     optional: false

volumeMounts: []
# - name: foo
#   mountPath: "/etc/foo"
#   readOnly: true

nodeSelector: {}

tolerations: []

affinity: {}
